{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQrIs5ykfmqKfRC2Jy/ewr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"leQH8XFMIhzN","executionInfo":{"status":"ok","timestamp":1728479750433,"user_tz":-330,"elapsed":711,"user":{"displayName":"AKSHITA GARG","userId":"12410317472217733424"}},"outputId":"e66357a2-923e-4592-ec51-00cf6e78786a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted classes array: [1. 0. 1. 1. 0. 2. 2. 1. 0. 2. 2. 2. 1. 0. 0. 2. 0. 0. 0. 1. 1. 2. 2. 0.\n"," 1. 0. 0. 0. 1. 2.]\n","Analysing our model.\n","[[12.  0.  0.]\n"," [ 0.  9.  2.]\n"," [ 0.  0.  7.]]\n","Accuracy: [1.         0.93333333 0.93333333]\n","Precision: [1.         1.         0.77777778]\n","Recall: [1.         0.81818182 1.        ]\n","F1 Score: [1.    0.9   0.875]\n"]}],"source":["import numpy as np\n","import sklearn as sk\n","from sklearn.datasets import load_iris\n","iris=load_iris()\n","\n","# Shuffling the dataset randomly\n","perm=np.random.permutation(len(iris.data))\n","x_iris=iris.data[perm]\n","y_iris=iris.target[perm]\n","\n","#Splitting manually into train and test set\n","x_iris_train=x_iris[:120]\n","y_iris_train=y_iris[:120]\n","x_iris_test=x_iris[120:]\n","y_iris_test=y_iris[120:]\n","\n","predicted_classes = np.empty((len(x_iris_test))) #Initialising an empty numpy array of size=number of test samples\n","\n","for n, sample in enumerate(x_iris_test):  #traverse along with indexes through test set\n","  q = np.empty((len(x_iris_train), 2))   #an array q of rows=number of train samples to store distance from each train sample\n","  for x, train_sample in enumerate(x_iris_train):\n","    #calculating \"distance\"\n","    p = sample - train_sample\n","    s = np.dot(p, p)\n","    #store result in q\n","    q[x] = [s, y_iris_train[x]]\n","  #sorting data column wise\n","  sorted_indices = np.argsort(q[:, 0]) #returns indices that would sort the array with respect to column 0\n","  sorted_q = q[sorted_indices]\n","  a = sorted_q[0:5] #get first 5 elements : 5NN\n","  j = a[:, 1] #get classes of those neighbours\n","  #now simply count number of occurences of each class in J and classify sample to majority\n","  count0 = 0\n","  count1 = 0\n","  count2 = 0\n","  for k in j:\n","    if k == 0:  count0 += 1\n","    elif k == 1:  count1 += 1\n","    else:   count2 += 1\n","  if count0 > count1 and count0 > count2:\n","    predicted_classes[n] = 0\n","  elif count1 > count0 and count1 > count2:\n","    predicted_classes[n] = 1\n","  else:\n","    predicted_classes[n] = 2\n","\n","#print the whole predicted class array\n","print(\"Predicted classes array:\", predicted_classes)\n","\n","#Analysis of this result using 3 class confusion matrix\n","print(\"Analysing our model.\")\n","\n","def calculate_confusion_matrix(y_true, y_pred, num_classes):\n","  # Initialize the confusion matrix of size(nXn) where n=number of classes\n","  conf_matrix = np.zeros((num_classes, num_classes))\n","  # Iterate over each sample to create confusion matrix with respect to A\n","  #.     A.   B.   C.   Predicted\n","  #.  A  TP   FN   FN\n","  #   B  FP   TN   TN\n","  #   C  FP   TN   TN\n","  for true_class, pred_class in zip(y_true, y_pred):\n","    #Update the corresponding cell in the confusion matrix\n","    conf_matrix[int(true_class), int(pred_class)] += 1\n","  return conf_matrix\n","def calculate_metrics(conf_matrix):\n","  #Calculating true positives, false positives, false negatives for each class\n","  TP = np.diag(conf_matrix)  #obtained as a matrix of order 1xn\n","  FP = np.sum(conf_matrix, axis=0) - TP   #sum of column-TP\n","  FN = np.sum(conf_matrix, axis=1) - TP   #sum of row -TP\n","  # calculating true negatives for each class\n","  TN = np.sum(conf_matrix) - (TP + FP + FN) #remaining part\n","\n","  # calculating accuracy for each class\n","  accuracy = (TP + TN) / np.sum(conf_matrix)\n","\n","  # calculating precision for each class\n","  precision = TP / (TP + FP)\n","\n","  # calculating recall for each class\n","  recall = TP / (TP + FN)\n","\n","  # calculating F1 score for each class\n","  f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","  return accuracy, precision, recall, f1_score\n","\n","\n","conf_matrix=calculate_confusion_matrix(y_iris_test,predicted_classes,3)\n","accuracy, precision, recall, f1_score = calculate_metrics(conf_matrix)\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1_score)"]}]}