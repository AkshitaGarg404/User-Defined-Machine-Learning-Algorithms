{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOOtzCxhlv/8xI4bx3bL2o5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBC7cTpwgP-2","executionInfo":{"status":"ok","timestamp":1728482520313,"user_tz":-330,"elapsed":446,"user":{"displayName":"AKSHITA GARG","userId":"12410317472217733424"}},"outputId":"b4a52487-99ab-4b47-b7e9-196cae215a0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions: [0, 0, 1, 0, 0, 2, 0, 2, 1, 1, 2, 2, 0, 1, 1, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 2, 0, 0, 2, 0]\n","Accuracy: 1.0\n"]}],"source":["import numpy as np\n","import sklearn as sk\n","from sklearn.datasets import load_iris\n","\n","def covmat(data):\n","  num_features=data.shape[1] #get Number of features\n","  num_sample=len(data)  #get Number of samples\n","  cov_matrix = np.zeros((num_features, num_features)) #create cov matrix\n","  mean=np.sum(data,axis=0)/num_sample #mean for all collumns\n","  for i in range (num_features):\n","    for j in range (num_features):\n","      cov=0;\n","      for k in range (num_sample): #for each sample take sum\n","        cov+=((data[k,i]-mean[i])*(data[k,j]-mean[j]))/(num_sample-1)\n","        cov_matrix[i,j]=cov\n","  return cov_matrix\n","\n","\n","def bayesian(x_train, y_train, x_test, y_test):\n","  # computing class priors\n","  unique_classes, class_counts = np.unique(y_train, return_counts=True) #returns all unique classes with their counts\n","  class_priors = class_counts / len(y_train)  #find probabilty of each class\n","  # Computing class conditional probabilities\n","  class_mean_inv = {} #to store mean and inverse of all classes\n","  for c in unique_classes:\n","    class_indices = np.where(y_train == c)[0] #returns list of all indices of class c\n","    class_data = x_train[class_indices] #get all train data of class c\n","    mean = np.mean(class_data, axis=0) #find mean of that class\n","    cov_matrix = covmat(class_data) #find cov matrix of that class\n","    inverse_covmat = np.linalg.inv(cov_matrix)  #inverse of covariance matrix of that class\n","    class_mean_inv[c] = {'mean': mean, 'inverse_covmat': inverse_covmat}\n","  #To store predictions\n","  predictions = []\n","  for sample in x_test: #now predict for all test samples as data is ready\n","    posteriors = []  #to store posterior probabilites of sample wrt all classes\n","    for c in unique_classes:\n","      mean = class_mean_inv[c]['mean']\n","      inverse_covmat = class_mean_inv[c]['inverse_covmat']\n","      prior = class_priors[c]\n","      d = sample.shape[0] # Dimensionality of the sample\n","      diff = sample - mean\n","      # calculating the exponent term of the probability density function\n","      exponent = -0.5 * np.dot(np.dot(diff, inverse_covmat), diff.T)\n","      # calculating the determinant of the covariance matrix\n","      det_covmat = np.linalg.det(inverse_covmat)\n","      #calculating the probability density function\n","      class_prob = np.exp(exponent) / np.sqrt((2 * np.pi) ** d * np.abs(det_covmat))\n","      #Multiplying by the prior probability of the class\n","      posterior = prior * class_prob\n","      #adding posterior prob to list\n","      posteriors.append(posterior)\n","    # selecting the class with the highest posterior probability\n","    predicted_class = unique_classes[np.argmax(posteriors)] #take indice of max of all posterior prob\n","    predictions.append(predicted_class)\n","\n","  # calculating accuracy\n","  accuracy = np.mean(predictions == y_test)\n","  return predictions, accuracy\n","\n","def test_train_split(data,target,split_perc):\n","  perm=np.random.permutation(len(data)) #to get random permutation of 0 to len-1\n","  x_shuff=data[perm]    #obtain shuffled data\n","  y_shuff=target[perm]    #obtain shuffled targets\n","  #get the index till which data is in train set\n","  n=round((((100-split_perc)*0.01))*len(data)) #round is used to round off to the nearest integer\n","  x_train=x_shuff[:n] #take starting n elements of shuffled data\n","  y_train=y_shuff[:n]\n","  x_test=x_shuff[n:] #take remaining elements of shuffled data\n","  y_test=y_shuff[n:]\n","  return x_train, y_train, x_test, y_test\n","\n","iris=load_iris()\n","x_train,y_train,x_test,y_test=test_train_split(iris.data,iris.target,20)\n","predictions, accuracy = bayesian(x_train, y_train, x_test, y_test)\n","print(\"Predictions:\", predictions)\n","print(\"Accuracy:\", accuracy)"]},{"cell_type":"code","source":[],"metadata":{"id":"9RrnZ0V-iEqA"},"execution_count":null,"outputs":[]}]}