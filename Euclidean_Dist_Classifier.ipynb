{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBOAdtnYcNkyWRU187OMGj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhC8gGb6l4tx","executionInfo":{"status":"ok","timestamp":1728484770058,"user_tz":-330,"elapsed":423,"user":{"displayName":"AKSHITA GARG","userId":"12410317472217733424"}},"outputId":"7f3aeddb-f042-45f7-e90b-5ea0103babdf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2, 2, 0, 0, 0, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 2, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n","Analysing our model.\n","[[17.  0.  0.]\n"," [ 0.  4.  1.]\n"," [ 0.  1.  7.]]\n","Accuracy: [1.         0.93333333 0.93333333]\n","Precision: [1.    0.8   0.875]\n","Recall: [1.    0.8   0.875]\n","F1 Score: [1.    0.8   0.875]\n"]}],"source":["import numpy as np\n","import sklearn as sk\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split  #inbuilt data split tool\n","\n","def euclidian(x_test,x_train,y_train):\n","  num_sample=x_train.shape[0] #number of training samples\n","\n","  unique_classes, class_counts = np.unique(y_train, return_counts=True) #returns all unique classes with their counts\n","  class_mean = []#to store mean of all classes\n","  for n,c in enumerate(unique_classes):\n","    class_indices = np.where(y_train == c)[0] #returns list of all indices of class c\n","    class_data = x_train[class_indices] #get all train data of class c\n","    mean = np.mean(class_data, axis=0) #find mean of that class\n","    class_mean.append(mean)\n","\n","  predicted=[] #to store predicted classes\n","  #To store predictions\n","  for test_sample in x_test:\n","    a=[] #to store all distances\n","    for u in class_mean:\n","      diff=test_sample-u #(x-meani)\n","      dist=np.sqrt(np.dot(diff,diff.T)) #||(x-meani)||\n","      a.append(dist)\n","    predicted_class=np.argmin(a)\n","    predicted.append(predicted_class)\n","  return predicted\n","\n","def test_train_split(data,target,split_perc):\n","  perm=np.random.permutation(len(data)) #to get random permutation of 0 to len-1\n","  x_shuff=data[perm]    #obtain shuffled data\n","  y_shuff=target[perm]    #obtain shuffled targets\n","  #get the index till which data is in train set\n","  n=round((((100-split_perc)*0.01))*len(data)) #round is used to round off to the nearest integer\n","  x_train=x_shuff[:n] #take starting n elements of shuffled data\n","  y_train=y_shuff[:n]\n","  x_test=x_shuff[n:] #take remaining elements of shuffled data\n","  y_test=y_shuff[n:]\n","  return x_train, y_train, x_test, y_test\n","\n","# irisData = load_iris()\n","\n","# # Create feature and target arrays\n","# X = irisData.data\n","# y = irisData.target\n","\n","# # Split into training and test set\n","# X_train, X_test, y_train, y_test = train_test_split(\n","#              X, y, test_size = 0.2, random_state=15)\n","iris=load_iris()\n","x_train,y_train,x_test,y_test=test_train_split(iris.data,iris.target,20)\n","predicted=euclidian(x_test, x_train, y_train)\n","print(predicted)\n","\n","#Analysis of this result using 3 class confusion matrix\n","print(\"Analysing our model.\")\n","\n","def calculate_confusion_matrix(y_true, y_pred, num_classes):\n","  # Initialize the confusion matrix of size(nXn) where n=number of classes\n","  conf_matrix = np.zeros((num_classes, num_classes))\n","  # Iterate over each sample to create confusion matrix with respect to A\n","  #.     A.   B.   C.   Predicted\n","  #.  A  TP   FN   FN\n","  #   B  FP   TN   TN\n","  #   C  FP   TN   TN\n","  for true_class, pred_class in zip(y_true, y_pred):\n","    #Update the corresponding cell in the confusion matrix\n","    conf_matrix[int(true_class), int(pred_class)] += 1\n","  return conf_matrix\n","def calculate_metrics(conf_matrix):\n","  #Calculating true positives, false positives, false negatives for each class\n","  TP = np.diag(conf_matrix)  #obtained as a matrix of order 1xn\n","  FP = np.sum(conf_matrix, axis=0) - TP   #sum of column-TP\n","  FN = np.sum(conf_matrix, axis=1) - TP   #sum of row -TP\n","  # calculating true negatives for each class\n","  TN = np.sum(conf_matrix) - (TP + FP + FN) #remaining part\n","\n","  # calculating accuracy for each class\n","  accuracy = (TP + TN) / np.sum(conf_matrix)\n","\n","  # calculating precision for each class\n","  precision = TP / (TP + FP)\n","\n","  # calculating recall for each class\n","  recall = TP / (TP + FN)\n","\n","  # calculating F1 score for each class\n","  f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","  return accuracy, precision, recall, f1_score\n","\n","\n","conf_matrix=calculate_confusion_matrix(y_test,predicted,3)\n","accuracy, precision, recall, f1_score = calculate_metrics(conf_matrix)\n","print(conf_matrix)\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1 Score:\", f1_score)"]}]}